{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import iris\n",
    "import matplotlib.pyplot as plt\n",
    "import iris.pandas\n",
    "import iris.plot\n",
    "from statsmodels.tsa.stattools import acf\n",
    "import numpy as np\n",
    "# First define a dataset\n",
    "dataset = '/net/exo/landclim/PROJECTS/C3S/datadir/testdata/ehdb_t2m.nc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create artificial 1d timeseries data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            print(\"Creating artificial test data\")\n",
    "            # Create some test data\n",
    "            a = 50  # a.u.\n",
    "            nyears = 15\n",
    "            datapoints_per_year = 4      # For seasonal data\n",
    "            ndatapoints=nyears*datapoints_per_year\n",
    "            t = np.arange(ndatapoints)\n",
    "            b = 0.005 # a.u./year\n",
    "            # np.random.seed(5) # Uncomment this to change to 'pseudo-randomness'\n",
    "            c = np.random.random(ndatapoints) # Random \"noise\" in range[0,1]\n",
    "            nan_fraction = .4\n",
    "            add_nans = False\n",
    "            \n",
    "            # Create timeseries\n",
    "            y = a+b*t+c\n",
    "            \n",
    "            # Assign some nans\n",
    "            n_nans = int(nyears*nan_fraction)\n",
    "            \n",
    "            # Randomly assign nans\n",
    "            if add_nans:\n",
    "                nan_indices = random.sample(range(ndatapoints),n_nans)\n",
    "                for i in nan_indices:\n",
    "                    y[i] = np.nan\n",
    "            #TODO convert this to a timeseries        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For expanding trend diagnostics to 3D data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.81969982, 0.60438198, 0.4635709 , 0.37196933,\n",
       "       0.30878489, 0.26904969, 0.23902206, 0.2242374 , 0.21414912,\n",
       "       0.20646595, 0.19587822, 0.19014254, 0.18521866, 0.17253083,\n",
       "       0.16390064, 0.16093254, 0.16568077, 0.1680596 , 0.16510022,\n",
       "       0.14918026, 0.12688051, 0.11830024, 0.12733358, 0.13394592,\n",
       "       0.13586154, 0.13931137, 0.13988466, 0.12724877, 0.11092529,\n",
       "       0.10557254, 0.1020238 , 0.09298363, 0.08659728, 0.08737826,\n",
       "       0.0945111 , 0.0961407 , 0.09393335, 0.09112845, 0.09167982,\n",
       "       0.09508234])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class trend_utils_extra:\n",
    "    def __mann_kendall_trend__(self):\n",
    "        print(\"Calculating Mann-Kendall Trend\")\n",
    "        this_function = \"mann kendall trend\"\n",
    "        \n",
    "        # Set parameters\n",
    "        self.record_cutoff = 10\n",
    "\n",
    "        # Leave out nreduce for now\n",
    "        shape2d = self.sp_data.shape[1:]\n",
    "\n",
    "        # Create tuples containing all the combinations of indices\n",
    "        indexlist = list(it.product(range(shape2d[0]),range(shape2d[1])))\n",
    "        wrapdictlist = []\n",
    "        for indices in indexlist:\n",
    "            d = {}\n",
    "            d['indices'] = indices\n",
    "            wrapdictlist.append(d)\n",
    "        \n",
    "        pool = ProcessingPool()\n",
    "        \n",
    "        pool.ncpus = 20\n",
    "        mktest_output_list = pool.map(self.__wrap_mk_test__,wrapdictlist)\n",
    "        \n",
    "        # Now create arrays for data storage\n",
    "        h = np.empty(shape2d,dtype='int')\n",
    "        p = np.empty(shape2d,dtype='float')\n",
    "        z = np.empty(shape2d,dtype='float')\n",
    "        trend = np.empty(shape2d,dtype='int')\n",
    "        recordlength = np.empty(shape2d,dtype='int')\n",
    "        mask = np.empty(shape2d,dtype='int')\n",
    "        \n",
    "        # Now start unpacking the results\n",
    "        trendtext_to_intdict = {\n",
    "                'increasing' : 1,\n",
    "                'no trend' : 0,\n",
    "                'decreasing' : -1,\n",
    "                }\n",
    "        \n",
    "        for d in mktest_output_list:\n",
    "            i,j = d['indices']\n",
    "            trend[i,j] = trendtext_to_intdict[d['trend']]\n",
    "            h[i,j] = d['h']\n",
    "            p[i,j] = d['p']\n",
    "            z[i,j] = d['z']\n",
    "            mask[i,j] = d['mask']\n",
    "            recordlength[i,j] = d['recordlength']\n",
    "\n",
    "        vardict = {\n",
    "            'trend' : trend,\n",
    "            'h' : h,\n",
    "            'p' : p,\n",
    "            'z' : z,\n",
    "            'recordlength' : recordlength,\n",
    "            'mask' : mask\n",
    "        }\n",
    "        \n",
    "        # New way of saving\n",
    "        cube2d = self.sp_data[0,:,:].copy()\n",
    "        # Add the mask\n",
    "        cube2d.data.mask = mask\n",
    "        \n",
    "        newcubes = []\n",
    "        for key in vardict:\n",
    "            thiscube = cube2d.copy()\n",
    "            thiscube.data = vardict[key]\n",
    "            thiscube.varname = key\n",
    "            thiscube.var_name = key\n",
    "            thiscube.rename(key)\n",
    "            thiscube.units=''\n",
    "            newcubes.append(thiscube)\n",
    "\n",
    "        list_of_plots=[]\n",
    "        print(\"Starting the plotting\")\n",
    "        for key,cube in zip(vardict,newcubes):\n",
    "            # define filename\n",
    "            filename = self.__plot_dir__ + os.sep + self.__basic_filename__ + \"MK_\"+key+ \".\" + self.__output_type__\n",
    "            print(\"plotting: \",filename)\n",
    "            list_of_plots.append(filename)\n",
    "\n",
    "\n",
    "            # initialize the figure\n",
    "            fig = plt.figure()\n",
    "            # intialize the axis where we plot\n",
    "            ax = [plt.subplot(1,1,1)]\n",
    "\n",
    "            # Modify the coordinates\n",
    "#                x=Plot2D(cube)\n",
    "#                x.plot(ax=ax, title=\" \".join([self.__dataset_id__[indx] for indx in [0,2,1,3]]) + \" (\" + self.__time_period__ + \")\")\n",
    "#            except:\n",
    "            cube.coord('latitude').points = cube.coord('latitude').points-0.0001\n",
    "            cube.coord('longitude').points = cube.coord('longitude').points-0.0001\n",
    "            x=Plot2D(cube)\n",
    "            x.plot(ax=ax, title=\" \".join([self.__dataset_id__[indx] for indx in [0,2,1,3]]) + \" (\" + self.__time_period__ + \")\")\n",
    "\n",
    "            # call the plot\n",
    "            \n",
    "            # save figure\n",
    "            fig.savefig(filename)\n",
    "            # close figure\n",
    "            plt.close(fig.number)\n",
    "    \n",
    "            ESMValMD(\"meta\",\n",
    "                     filename,\n",
    "                     self.__basetags__ + ['DM_global', 'C3S_MannKendall'],\n",
    "                     # caption below EDIT!\n",
    "                     str(\"Mann Kendall trend - \"+ key + ' of ' + self.__varname__ + ' for the data set \"' + \"_\".join(self.__dataset_id__) + '\" (' + self.__time_period__ + ')'),\n",
    "                     # identifier EDIT!\n",
    "    '#C3S' + \"igr\" + self.__varname__,\n",
    "                     self.__infile__,\n",
    "                     self.diagname,\n",
    "                     self.authors)\n",
    "        del newcubes\n",
    "        self.__do_report__(content={\"plots\":list_of_plots},filename=this_function.upper())\n",
    "            \n",
    "    def __wrap_mk_test__(self,wrapdict):\n",
    "        print(str(datetime.datetime.now())+\": starting new task\")\n",
    "        #data = wrapdict['data']\n",
    "        indices = wrapdict['indices']\n",
    "        i,j = indices\n",
    "        data_column = self.sp_data[:,i,j]\n",
    "        data_cleaned = data_column.data.compressed()\n",
    "        # Create a new dict to return\n",
    "        d = {}\n",
    "        d['recordlength'] = data_cleaned.size\n",
    "        d['indices'] = indices\n",
    "        if d['recordlength'] > self.record_cutoff: \n",
    "            d['trend'],d['h'],d['p'],d['z'] = self.__mk_test__(data_cleaned)\n",
    "            d['mask'] = 0\n",
    "        else:\n",
    "            d['trend'],d['h'],d['p'],d['z'] = 'no trend',0,1.0,0.0\n",
    "            d['mask'] = 1\n",
    "        return d\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consistency\n",
    "class TrendInspector:\n",
    "    def __init__(self):\n",
    "        print(\"Hello, looking forward to inspect the trends! :-)\")\n",
    "        self.c_score = 0\n",
    "    def __inspect__(self,inspectme):\n",
    "        inspectionlist = [inspectme]\n",
    "        while inspectionlist:\n",
    "            inspectme = inspectionlist.pop(0)\n",
    "            if self.__check_consistency__(inspectme):\n",
    "                pass\n",
    "                #self.c_score += 1\n",
    "                # Now split the dataset\n",
    "                #TODO only split while above a certain treshold\n",
    "                #a,b = copy.deepcopy(inspectme),copy.deepcopy(inspectme) # Create two copies\n",
    "                #a.subset(slice('1902','1960')) # First half of dataset\n",
    "                #b.subset(slice('1961','2010'))\n",
    "                #inspectionlist.append([a,b])\n",
    "                # For this timelength the trend tests were found to be consistent. Now split in two and check if it is still consistent.\n",
    "        self.__close_and_summarize__()\n",
    "    def __check_consistency__(self,inspectme):\n",
    "        if inspectme.stats_summary['trend_linear']['trend']==inspectme.stats_summary['trend_mannkendall']['trend']:\n",
    "            print(\"Two trend methods\")\n",
    "            #self.c_score += 1\n",
    "            #return True\n",
    "        elif inspectme.stats_summary['trend_linear']['trend']+inspectme.stats_summary['trend_mannkendall']['trend']==0:\n",
    "            return False\n",
    "    def __close_and_summarize__(self):\n",
    "        print(\"The score for this dataset is: {0}\".format(self.c_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
